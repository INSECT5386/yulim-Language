import json
import numpy as np
from tqdm import tqdm
from gensim.models import Word2Vec
import sentencepiece as spm
from sklearn.metrics.pairwise import cosine_similarity
import os

# ëª¨ë¸ ë¡œë“œ
sp = spm.SentencePieceProcessor()
sp.load("spm.model")
model = Word2Vec.load("respiso.model")

# ë¬¸ì¥ â†’ ë²¡í„°
def sentence_vector(sentence, model, sp):
Â  Â  tokens = sp.encode_as_pieces(sentence)
Â  Â  vecs = [model.wv[tok] for tok in tokens if tok in model.wv]
Â  Â  if not vecs:
Â  Â  Â  Â  return np.zeros(model.vector_size)
Â  Â  return np.mean(vecs, axis=0)

# FAQ ë°ì´í„°ë¥¼ ì œë„ˆë ˆì´í„°ë¡œ ì½ê¸°
def stream_faq(file_path):
Â  Â  with open(file_path, "r", encoding="utf-8") as f:
Â  Â  Â  Â  for line in f:
Â  Â  Â  Â  Â  Â  item = json.loads(line)
Â  Â  Â  Â  Â  Â  conv = item.get("conversations", [])
Â  Â  Â  Â  Â  Â  if len(conv) >= 2:
Â  Â  Â  Â  Â  Â  Â  Â  q = [c["value"] for c in conv if c["from"] == "human"]
Â  Â  Â  Â  Â  Â  Â  Â  a = [c["value"] for c in conv if c["from"] == "gpt"]
Â  Â  Â  Â  Â  Â  Â  Â  if q and a:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  yield {"question": q[0], "answer": a[0]}

# ì „ì²´ ë¼ì¸ ìˆ˜ ì„¸ê¸° (memmap í¬ê¸° ì„¤ì •ìš©)
def count_faq_lines(file_path):
Â  Â  with open(file_path, "r", encoding="utf-8") as f:
Â  Â  Â  Â  return sum(1 for _ in f)

# ìŠ¤íŠ¸ë¦¬ë° ì €ì¥
def build_memmap_vectors(jsonl_path, output_path, model, sp):
Â  Â  total = count_faq_lines(jsonl_path)
Â  Â  dim = model.vector_size

Â  Â  print(f"ğŸ“¦ ì´ {total}ê°œì˜ FAQ ë¬¸ì¥ ì²˜ë¦¬ ì˜ˆì • (ë²¡í„° ì°¨ì›: {dim})")

Â  Â  vectors = np.memmap(output_path, dtype="float32", mode="w+", shape=(total, dim))

Â  Â  for i, faq in enumerate(tqdm(stream_faq(jsonl_path), total=total, desc="ë²¡í„°í™” ì¤‘")):
Â  Â  Â  Â  vec = sentence_vector(faq["question"], model, sp)
Â  Â  Â  Â  vectors[i] = vec

Â  Â  del vectors  # flush to disk
Â  Â  print(f"âœ… {output_path} ì €ì¥ ì™„ë£Œ!")

# ì±—ë´‡ ì‘ë‹µ í•¨ìˆ˜ (memmap ê¸°ë°˜)
def chatbot_response(user_input, model, sp, jsonl_path, vec_path):
Â  Â  user_vec = sentence_vector(user_input, model, sp).reshape(1, -1)
Â  Â  vectors = np.memmap(vec_path, dtype="float32", mode="r").reshape(-1, model.vector_size)
Â  Â  best_sim = -1
Â  Â  best_answer = None

Â  Â  with open(jsonl_path, "r", encoding="utf-8") as f:
Â  Â  Â  Â  for i, line in enumerate(f):
Â  Â  Â  Â  Â  Â  data = json.loads(line)
Â  Â  Â  Â  Â  Â  conv = data.get("conversations", [])
Â  Â  Â  Â  Â  Â  if len(conv) < 2:
Â  Â  Â  Â  Â  Â  Â  Â  continue
Â  Â  Â  Â  Â  Â  a = [c["value"] for c in conv if c["from"] == "gpt"]
Â  Â  Â  Â  Â  Â  if not a:
Â  Â  Â  Â  Â  Â  Â  Â  continue

Â  Â  Â  Â  Â  Â  sim = cosine_similarity(user_vec, vectors[i].reshape(1, -1))[0, 0]
Â  Â  Â  Â  Â  Â  if sim > best_sim:
Â  Â  Â  Â  Â  Â  Â  Â  best_sim = sim
Â  Â  Â  Â  Â  Â  Â  Â  best_answer = a[0]

Â  Â  return best_answer, best_sim

# ë©”ì¸
if not os.path.exists("faq_vectors.memmap"):
Â  Â  build_memmap_vectors("faq_dataset.jsonl", "faq_vectors.memmap", model, sp)

print("ğŸ¤– Respiso ì™„ì „ ìŠ¤íŠ¸ë¦¬ë° ì±—ë´‡ ì‹œì‘! (ì¢…ë£Œí•˜ë ¤ë©´ 'ì¢…ë£Œ')")
while True:
Â  Â  user_input = input("You: ").strip()
Â  Â  if user_input.lower() in ["ì¢…ë£Œ", "exit", "quit"]:
Â  Â  Â  Â  print("ğŸ‘‹ ì¢…ë£Œ!")
Â  Â  Â  Â  break
Â  Â  answer, sim = chatbot_response(user_input, model, sp, "faq_dataset.jsonl", "faq_vectors.memmap")
Â  Â  print(f"Bot ({sim:.3f}): {answer}")
